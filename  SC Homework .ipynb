{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41504485",
   "metadata": {},
   "source": [
    "## SC Homework  \n",
    "#### December 2022\n",
    "\n",
    "### Stream 1: Machine Learning  \n",
    "By José Alejandro López\n",
    "   josalelg@hotmail.com\n",
    "   \n",
    "Project for the interview of december the 3rd 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb576c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "from scipy.stats import entropy\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from torchvision import  models\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8397ed1",
   "metadata": {},
   "source": [
    "#### Task 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b81b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# ======= Task 1. ======= \n",
    "\n",
    "ROOT_PATH = os.path.dirname(os.getcwd())\n",
    "RANDOM_SEED = 123\n",
    "\n",
    "\n",
    "def drop_labels(dataset_labels, proportion):\n",
    "    \"\"\"Drop a desired proportion of labels from a labels list   .\n",
    "\n",
    "    Args:\n",
    "        dataset_labels (list): list of integers\n",
    "        proportion (float): proportion of tags to be dropped\n",
    "\n",
    "    Returns:\n",
    "        pandas data frame: Original labels and in sample boolean tag\n",
    "        ['dataset_labels', 'in_sample']\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(dataset_labels, columns=['dataset_labels'])\n",
    "    df['in_sample'] = True\n",
    "    indexes_to_remove = df \\\n",
    "                            .sample(frac=proportion,\n",
    "                                    axis=0,\n",
    "                                    random_state = RANDOM_SEED \n",
    "                                    ).index\n",
    "\n",
    "    df.loc[indexes_to_remove, 'in_sample']=False\n",
    "\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444ee43a",
   "metadata": {},
   "source": [
    "#### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0795e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# ======= TASK 2 - Data cleaning ======= \n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "images_df = pd.DataFrame(None, columns=['data_set', 'filename', 'mode', 'size'])\n",
    "\n",
    "train_dir = os.path.join(ROOT_PATH, 'data','cars_train')\n",
    "test_dir = os.path.join(ROOT_PATH, 'data','cars_test')\n",
    "\n",
    "idx = 0\n",
    "for directory in [train_dir, test_dir]: \n",
    "    for file in os.listdir(directory):\n",
    "        \n",
    "        filename = os.fsdecode(file)\n",
    "        image_path = os.path.join(directory, filename)\n",
    "        with Image.open(image_path) as image_pil:\n",
    "            mode, size = image_pil.mode, image_pil.size\n",
    "        dir_name = os.path.basename(directory)\n",
    "        \n",
    "        # Populate df with image filename, mode and size   \n",
    "        images_df.loc[idx,:] = dir_name, filename, mode, str(size)\n",
    "        \n",
    "        if mode != 'RGB':  # Remove unwanted imges\n",
    "            print(f'Removing image {idx} {dir_name}/{filename}')\n",
    "            os.remove(image_path)\n",
    "   \n",
    "        idx += 1            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4cc8b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_set    mode\n",
      "cars_test   RGB     8025\n",
      "cars_train  RGB     8126\n",
      "Name: mode, dtype: int64\n",
      "     data_set   filename mode          size\n",
      "0  cars_train  00001.jpg  RGB    (600, 400)\n",
      "1  cars_train  00002.jpg  RGB    (900, 675)\n",
      "2  cars_train  00003.jpg  RGB    (640, 480)\n",
      "3  cars_train  00004.jpg  RGB  (2100, 1386)\n",
      "4  cars_train  00005.jpg  RGB    (144, 108)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Some images are in gray, they have image_pil.mode 'L' instead of 'RGB'\n",
    "print(images_df.groupby('data_set')['mode'].value_counts()) \n",
    "print(images_df.head())\n",
    "\n",
    "# data_set    mode\n",
    "# cars_test   RGB     8025\n",
    "#             L         16\n",
    "# cars_train  RGB     8126\n",
    "#             L         18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b73af1",
   "metadata": {},
   "source": [
    "#### Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "255df852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josal\\Anaconda3\\envs\\py38genuse\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\josal\\Anaconda3\\envs\\py38genuse\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "#%%\n",
    "# ======= TASK 3 - Dataset representation ======= \n",
    "\n",
    "# %%\n",
    "# Load train set labels and merge them with images_df\n",
    "labels = pd.read_csv(os.path.join(ROOT_PATH, 'data', 'train_perfect_preds.txt')\n",
    "                     ,header=None, names=['labels'])\n",
    "labels['data_set'] = 'cars_train'\n",
    "labels['labels'] = labels['labels'].astype(str)\n",
    "\n",
    "labels = labels.reset_index().rename({'index':'filename'}, axis=1)\n",
    "labels['filename'] = labels['filename'].apply(lambda x:  f'{x+1:05d}.jpg')\n",
    "\n",
    "\n",
    "# Merge with images df\n",
    "images_tags_df = images_df.merge(labels, on=['data_set','filename'], how='left')\n",
    "\n",
    "# Set up the dictionary with required structure\n",
    "# {1: {'embedding': <np.ndarray>, 'class_idx': <int>, ‘labelled': <boolean or int>\n",
    "embeddings_dic = {}\n",
    "\n",
    "# Load Resnet18 model\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = torch.nn.Identity()\n",
    "# print(list(model.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "027fc6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Populate the dictionary\n",
    "\n",
    "embeddings_dic = {}\n",
    "\n",
    "idx = 1\n",
    "total_files = len(os.listdir(directory))\n",
    "\n",
    "# for directory in [train_dir]: \n",
    "#     for file in os.listdir(directory):        \n",
    "                    \n",
    "#         filename = os.fsdecode(file)\n",
    "#         image_path = os.path.join(directory, filename)\n",
    "#         with Image.open(image_path) as image_pil:\n",
    "#             mode, size = image_pil.mode, image_pil.size\n",
    "#             image_tensor = torchvision.transforms.functional.to_tensor(image_pil)\n",
    "#             embedding_torch = model(image_tensor.unsqueeze(0))\n",
    "#             embedding_np = embedding_torch.detach().cpu().numpy()\n",
    "            \n",
    "#         dset_mask = images_tags_df['data_set']=='cars_train'\n",
    "#         filename_mask = images_tags_df['filename']==filename\n",
    "#         class_label = images_tags_df.loc[dset_mask & filename_mask,'labels'].values[0]        \n",
    "#         embeddings_dic[idx]={'embedding':embedding_np,\n",
    "#                              'class_idx':class_label,\n",
    "#                              'labelled':1} \n",
    "        \n",
    "#         if (idx-1)%500==0: # Output partial completion\n",
    "#             print(f'embedding image {idx} of {total_files}....')               \n",
    "#         idx+=1\n",
    "\n",
    "# # Save dicionary using torch\n",
    "# dic_path = os.path.join(ROOT_PATH, 'data',  'embeddings.pt')\n",
    "# torch.save(embeddings_dic, dic_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e7bfb",
   "metadata": {},
   "source": [
    "#### Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbb2ffef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data size: 8126\n",
      "(8126, 2)\n",
      "   dataset_labels  in_sample\n",
      "0              14       True\n",
      "1               3       True\n",
      "2              91       True\n",
      "3             134       True\n",
      "4             106      False\n",
      "Sample data size: 3250\n",
      "New data labelled proportion: 0.4\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# ======= TASK 4 - Build a partially labelled dataset ======\n",
    "dic_path = os.path.join(ROOT_PATH, 'data',  'embeddings.pt')\n",
    "full_data = torch.load(dic_path)\n",
    "print(f'Loaded data size: {len(full_data.keys())}')\n",
    "\n",
    "\n",
    "all_labels = [int(full_data[k]['class_idx']) for k in full_data.keys()]\n",
    "labels_dropped = drop_labels(all_labels, proportion=0.6)\n",
    "#labels_dropped['in_sample'] = labels_dropped['in_sample']*1 \n",
    "print(labels_dropped.shape)\n",
    "print(labels_dropped.head())\n",
    "#%%\n",
    "# Create data set with 40% of the data being labeled\n",
    "sample_data = {}\n",
    "for k,include in zip(full_data.keys(), labels_dropped['in_sample']):\n",
    "    if include:\n",
    "        sample_data[k] = {kk:v for kk,v in full_data[k].items()}\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "print(f'Sample data size: {len(sample_data.keys())}') \n",
    "sample_porportion = len(sample_data.keys()) / len(full_data.keys())\n",
    "print(f'New data labelled proportion: {sample_porportion:.4}')\n",
    "#%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa103bfa",
   "metadata": {},
   "source": [
    "#### Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "413787bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= TASK 5 - Create train/validation split ======= \n",
    "\n",
    "def split_data(datase_inputs, dataset_labels, training_proportion = 0.8):\n",
    "    \"\"\"Function to split data into train and test subsets.\n",
    "\n",
    "    Args:\n",
    "        datase_inputs iterable: Input explanatory features\n",
    "        dataset_labels iterable: Category tags\n",
    "        training_proportion (float, optional): Train set proportion size. Defaults to 0.8.\n",
    "\n",
    "    Returns:\n",
    "        iterables: X_train, X_test, y_train, y_test data subsets corresponding to \n",
    "         training_inputs, test_inputs, training_labels, test_labels.\n",
    "    \"\"\"\n",
    "    X, y = datase_inputs, dataset_labels\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y,\n",
    "                                            test_size=1-training_proportion,\n",
    "                                            random_state=RANDOM_SEED\n",
    "                                        )\n",
    "\n",
    "    X_train, X_test = np.stack(X_train), np.stack(X_test) # Convert to arrays     \n",
    "    # Slice to reshape from                                   \n",
    "    return X_train[:, 0, :], X_test[:, 0, :], np.array(y_train), np.array(y_test)\n",
    "\n",
    "\n",
    "inputs = [sample_data[k]['embedding']for k in sample_data.keys()]\n",
    "labels = [sample_data[k]['class_idx'] for k in sample_data.keys()]\n",
    "# print(len(inputs), len(labels))\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(inputs, labels, training_proportion = 0.8)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36e98341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sgdclassifier', SGDClassifier(loss='log'))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "# ======= TASK 6 Experiment(s) to convince clients that more labels will improve model performance = \n",
    "\n",
    "\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "\n",
    "clf = make_pipeline(#StandardScaler(),\n",
    "                    SGDClassifier(max_iter=1000, tol=1e-3,\n",
    "                    loss = 'log'))\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c5ad8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023076923076923078"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "\n",
    "# Make predictions and get performance metrics\n",
    "\n",
    "train_preds = clf.predict(X) #[[-0.8, -1]]\n",
    "train_probas = clf.predict_proba(X)\n",
    "test_preds  = clf.predict(X_test)\n",
    "test_pobas  = clf.predict_proba(X_test)\n",
    "\n",
    "metrics.precision_score(y_test, test_preds, average='micro')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b9bc8",
   "metadata": {},
   "source": [
    "#### Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00711c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual and target sizes: 3250 5282. To add: 2032\n"
     ]
    }
   ],
   "source": [
    "#%%\n",
    "# ======= TASK 7 - Active learning to select new instances to be labelled =======\n",
    "\n",
    "# Calculate entropy of the full data set\n",
    "all_embeddings_np = np.array([full_data[k]['embedding'] for k in full_data.keys()])[:, 0, :]\n",
    "\n",
    "\n",
    "# Predict probabiities on full data set\n",
    "full_probas = clf.predict_proba(all_embeddings_np)\n",
    "full_probas.shape\n",
    "\n",
    "# Calculate entropies \n",
    "entropies = np.array([entropy(p) for p in full_probas])\n",
    "entropies.shape\n",
    "\n",
    "id_position_pd = pd.DataFrame({'id':list(full_data.keys()),\n",
    "                               'position': np.argsort(entropies)[::-1],\n",
    "                               'entropy': entropies})\n",
    "\n",
    "\n",
    "# Calculate the number of K of examples to add\n",
    "actual_size = len(sample_data)\n",
    "target_size = math.ceil(len(full_data)*.65)\n",
    "n_top = target_size - actual_size\n",
    "print(f'Actual and target sizes: {actual_size} {target_size}. To add: {n_top}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dcff166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get keys not being in the sample\n",
    "in_sample_ids = [i for i in sample_data.keys()]\n",
    "out_sample_ids = set(id_position_pd['id']).difference(set(in_sample_ids))\n",
    "\n",
    "len(set(in_sample_ids).intersection(out_sample_ids)) # Check 0 intersect\n",
    "\n",
    "top_out_sample_pd = id_position_pd \\\n",
    "                        .loc[id_position_pd['id'].isin(out_sample_ids),:] \\\n",
    "                        .sort_values(by='position') \\\n",
    "                        .head(n_top)                            \n",
    "\n",
    "\n",
    "top_out_sample_ids = sorted(top_out_sample_pd['id'])          \n",
    "top_out_sample_ids[0:4]\n",
    "\n",
    "extended_sample_ids = sorted([i for i in set(in_sample_ids).union(set(top_out_sample_ids))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44baf323",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "# Then create the new data set\n",
    "\n",
    "sample_data2 = {}\n",
    "for i in extended_sample_ids:\n",
    "        sample_data2[i] = {k:v for k,v in full_data[i].items()}\n",
    "\n",
    "# list(sample_data2.keys())[0:15], len(sample_data2)\n",
    "#%%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014e8e4b",
   "metadata": {},
   "source": [
    "#### Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73d40d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('sgdclassifier', SGDClassifier(loss='log'))])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%\n",
    "# ======= TASK 8 - Final Model Evaluation =======\n",
    "\n",
    "inputs = [sample_data2[k]['embedding']for k in sample_data2.keys()]\n",
    "labels = [sample_data2[k]['class_idx'] for k in sample_data2.keys()]\n",
    "# print(len(inputs), len(labels))\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(inputs, labels, training_proportion = 0.8)    \n",
    "\n",
    "\n",
    "\n",
    "X = X_train\n",
    "y = y_train\n",
    "\n",
    "\n",
    "clf = make_pipeline(#StandardScaler(),\n",
    "                    SGDClassifier(max_iter=1000, tol=1e-3,\n",
    "                    loss = 'log'))\n",
    "\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cda741ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.007568590350047304"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions and get performance metrics\n",
    "\n",
    "train_preds = clf.predict(X) \n",
    "train_probas = clf.predict_proba(X)\n",
    "test_preds  = clf.predict(X_test)\n",
    "test_pobas  = clf.predict_proba(X_test)\n",
    "\n",
    "metrics.precision_score(y_test, test_preds, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7444471d",
   "metadata": {},
   "source": [
    "#### Final Results\n",
    "The evaluation metric used did not improved after increasing the training data set. It seems that augmentint the data size maybe it has been a good idea. However, the model could have not arrived to optimal values given that iterations were set very small to allow quick stop.  It would be necessary to revise the process to allow longest time and optimize hyperparameters to improve the quality of predictions. \n",
    "\n",
    "In this project I mainly try to stablish the full framework in order to pass by the whole process of data processing and modeling."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
